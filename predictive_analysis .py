# -*- coding: utf-8 -*-
"""predictive analysis

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1diIIQJHW0cCD28R2njmtaD6duVOe8Ppc

### Name : Ridopandi Sinaga
### Title : Mobile Price Classification
### Laggle dataset: https://www.kaggle.com/datasets/iabhishekofficial/mobile-price-classification
### Problem: Classification

## --------------------------------------------------------------------------------------------------------------------------------------

## Import library yang diperlukan
"""

import pandas as pd
import os, zipfile, shutil, PIL
from google.colab import files
import matplotlib.pyplot as plt
import numpy as np
import seaborn as sns
import pydotplus
import matplotlib.pyplot as plt
import matplotlib.image as pltimg
import matplotlib.patches as mpatches

from sklearn import datasets, linear_model, metrics
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_absolute_error
from sklearn.metrics import mean_squared_error
from sklearn.linear_model import Ridge
from sklearn.utils import resample
from sklearn.linear_model import LogisticRegression
from sklearn import tree
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import GridSearchCV
from sklearn.metrics import accuracy_score
from sklearn.metrics import precision_score
from sklearn.metrics import recall_score
from sklearn.metrics import confusion_matrix
from sklearn.metrics import roc_curve, auc
from sklearn.metrics import classification_report
from sklearn.svm import SVC
from sklearn.neighbors import KNeighborsClassifier
from sklearn.feature_selection import SelectKBest
from sklearn.feature_selection import f_classif
import scipy.stats as stats

"""## Dataset"""

!pip install -q kaggle

uploaded = files.upload()

!chmod 600 /content/kaggle.json

! KAGGLE_CONFIG_DIR=/content/ kaggle datasets download -d iabhishekofficial/mobile-price-classification

#unzip dataset
local_zip = '/content/mobile-price-classification.zip'
zip_ref = zipfile.ZipFile(local_zip, 'r')
zip_ref.extractall('/content')
zip_ref.close()

# Import
data = pd.read_csv('/content/train.csv')

# Cek keterangan dataset
data.info()

#cek statistik dataset
data.describe().T

"""Pada sc_width and px_height minimum valuenya 0. Artinya ada ketidakcocokan data karena tidak ada ponsel yang lebar nya 0 dan pixel kameranya 0."""

# Cek berapa banyak datum yg memiliki lebar layar  0.
print(data[data['sc_w']==0].shape[0])

#Cek berpa banyak datum px_height bernilai 0.
print(data[data['px_height']==0].shape[0])

# Drop 2 datum dengan px_height=0
data=data[data['px_height']!=0]



"""Karena kita baru saja ada drop data, kita harus mengatasi missing value, menggunakan algoritma K-nearest neighbors (KNN), untuk menentukan nilai yang paling sesuai menggantikan nilai yang hilang tersebut.

KNNImputer bekerja dengan mengidentifikasi tetangga terdekat dari setiap titik data yang memiliki nilai hilang dan kemudian mengambil nilai yang ada dari tetangga terdekat tersebut. Kemudian, KNNImputer menggunakan nilai-nilai yang diperoleh dari tetangga terdekat tersebut untuk menggantikan nilai yang hilang dalam dataset.

Sebelum menggunakan KNN Imputer kita perlu mengganti 0 dengan nilai NAN.
"""

# Replacing 0 with NAN so that we can implement KNN Imputer.
data['sc_w']=data['sc_w'].replace(0,np.nan)

# import KNN imputer frio sklearn
from sklearn.impute import KNNImputer
impute_knn = KNNImputer(n_neighbors=1)
data=pd.DataFrame(impute_knn.fit_transform(data),columns=data.columns)

# Checking shape
data.shape

# Checking How many observations having sc_w value as 0.
data[data['sc_w']==0].shape[0]

"""Ketidakcocokan data telah teratasi

# Exploratory Data Anaylsis
"""

# lets have look at our target variable's counts
price_range_values=data['price_range'].value_counts()
price_range_values

"""### Plot Data Price Range"""

labels = ["low cost", "medium cost", "high cost", "very high cost"]
price_range_values.plot.pie(explode=[0.05]*4, labels=labels, autopct='%1.1f%%', figsize=(6,4),fontsize=12)

price_range_values=data['price_range'].value_counts()
price_range_values

"""Keterangan:
* 0=low cost,
* 1=medium cost,
* 2=high cost,
* 3=very high cost.

Data hampir seimbang pada setiap kategori harga.Artinya kita tidak perlu standardisasi  atau imbalanced variabel lagi

### Plot RAM vs Price Range
"""

cs1 = ['#b788ca', '#9771b6', '#7e659f', '#582e67']
labelharga = ["Murah","Menengah Murah","Menegah Mahal","Mahal"]

plt.figure(figsize=(8,6))

data.groupby(['price_range'])['ram'].mean().plot(kind = 'bar', color = cs1, rot = 0)
plt.title('Rata-rata RAM Berdasarkan Harga Telepon Seluler', fontsize=18)
plt.xlabel('Harga Telepon Seluler', fontsize=14)
plt.ylabel('Rata-rata RAM (Mega Bytes)', fontsize=14)
plt.xticks([0, 1, 2, 3], ['Murah', 'Menengah', 'Mahal', 'Sangat Mahal'], fontsize=12)
plt.yticks(fontsize=12)

plt.show()

plt.figure(figsize=(8,6))

snsplot1 = sns.boxplot(x="price_range", y="ram", data=data, palette=cs1)
plt.title('Perbandingan RAM dengan Harga Telepon Seluler', fontsize=18)
plt.ylabel('Ukuran RAM (Mega Bytes)', fontsize=14)
plt.xlabel('Harga Telepon Seluler', fontsize=14)
plt.xticks([0, 1, 2, 3], ['Murah', 'Menengah', 'Mahal', 'Sangat Mahal'], fontsize=12)
plt.yticks(fontsize=12)

plt.show()

"""### Plot Battery Power vs Price Range"""

plt.figure(figsize=(8,6))

data.groupby(['price_range'])['battery_power'].mean().plot(kind = 'bar', color = cs1, rot = 0)
plt.title('Rata-rata Daya Baterai Berdasarkan Harga Telepon Seluler', fontsize=18)
plt.xlabel('Harga Telepon Seluler', fontsize=14)
plt.ylabel('Rata-rata Daya Baterai (mAh)', fontsize=14)
plt.xticks([0, 1, 2, 3], ['Murah', 'Menengah', 'Mahal', 'Sangat Mahal'], fontsize=12)
plt.yticks(fontsize=12)

plt.show()

plt.figure(figsize=(8,6))

snsplot2 = sns.boxplot(x="price_range", y="battery_power", data=data, palette=cs1)
plt.title('Perbandingan Daya Baterai dengan Harga Telepon Seluler', fontsize=18)
plt.ylabel('Daya Baterai (mAh)', fontsize=14)
plt.xlabel('Harga Telepon Seluler', fontsize=14)
plt.xticks([0, 1, 2, 3], ['Murah', 'Menengah', 'Mahal', 'Sangat Mahal'], fontsize=12)
plt.yticks(fontsize=12)

plt.show()

"""### Plot Screen Size vs Price Range"""

plt.figure(figsize=(8,6))
lbl1 = mpatches.Patch(color='#b788ca', label='Lebar (Pixel)')
lbl2 = mpatches.Patch(color='#9771b6', label='Tinggi (Pixel)')

data.groupby(['price_range'])['px_width','px_height'].mean().plot(kind = 'bar', color = cs1, rot = 0)
plt.title('Rata-rata Ukuran Layar Berdasarkan Harga Telepon Seluler', fontsize=14)
plt.xlabel('Harga Telepon Seluler', fontsize=10)
plt.ylabel('Rata-rata Ukuran Layar (Pixel)', fontsize=10)
plt.xticks([0, 1, 2, 3], ['Murah', 'Menengah', 'Mahal', 'Sangat Mahal'], fontsize=8)
plt.yticks(fontsize=8)

plt.legend(handles = [lbl1,lbl2], loc = 'upper left')

plt.show()

"""### Plot Both with 3G and 4G"""

# Mobiles have both 3G and 4G specifications.
three_g_and_4g_df=data[(data['three_g']==1) & (data['four_g']==1)]

three_g_and_4g_df['price_range'].value_counts()

price_range_counts = three_g_and_4g_df['price_range'].value_counts()

plt.figure(figsize=(6, 3))
plt.bar(price_range_counts.index, price_range_counts.values)
plt.xticks(ticks=[0,1,2,3],labels=['Low cost','medium cost','high cost','very high cost'])
plt.title('Mobiles with 3G and 4G features')
plt.xlabel('Price Range')
plt.ylabel('Count')
plt.show()



"""### Plot Data 3G"""

plt.figure(figsize=(4,3))

labels = ["3G",'Tidak 3G']
values = data['three_g'].value_counts().values
cs2 = ['#641d9b','#a384da']
plt.pie(values, labels=labels, autopct='%1.1f%%', startangle=90, colors=cs2, textprops={'fontsize': 14})
plt.title('Spesifikasi 3G Telepon Seluler', fontsize=18)

plt.show()

three_g_categories = list(set(data['three_g']))
price_range_counts = data['price_range'].value_counts()

plt.figure(figsize=(12,4))
sns.countplot(data=data, x='price_range', hue='three_g', order=price_range_counts.index, hue_order=three_g_categories)
plt.title("three_g v/s Price range")
plt.legend(loc='best')

"""### Plot Data 4G"""

plt.figure(figsize=(8,6))

labels = ["4G",'Tidak 4G']
values = data['four_g'].value_counts().values
cs2 = ['#641d9b','#a384da']
plt.pie(values, labels=labels, autopct='%1.1f%%', startangle=90, colors=cs2, textprops={'fontsize': 14})
plt.title('Spesifikasi 4G Telepon Seluler', fontsize=18)

plt.show()

four_g_categories = list(set(data['four_g']))
price_range_counts = data['price_range'].value_counts()

plt.figure(figsize=(12,4))
sns.countplot(data=data, x='price_range', hue='four_g', order=price_range_counts.index, hue_order=four_g_categories)
plt.title("four_g v/s Price range")
plt.legend(loc='best')

"""Majority of phones of only price range 2 dont have 4G service.

### No 3G and 4G
"""

No_3g_4G_df=data[(data['three_g']!=1) & (data['four_g']!=1)]
No_3g_4G_df.shape

price_range_counts = No_3g_4G_df['price_range'].value_counts()

plt.figure(figsize=(6, 3))
plt.bar(price_range_counts.index, price_range_counts.values)
plt.xticks(ticks=[0,1,2,3],labels=['Low cost','medium cost','high cost','very high cost'])
plt.title('Mobiles with no 3G and 4G features')
plt.xlabel('Price Range')
plt.ylabel('Count')
plt.show()

"""Its very obvious that low cost mobiles will not have 3G and 4G.
Mobiles with very high cost may have 5G. As we know technologies are changes everytime

### n_cores v/s price range
"""

n_cores_categories = list(set(data['n_cores']))
price_range_counts = data['price_range'].value_counts()

plt.figure(figsize=(12,4))
sns.countplot(data=data, x='price_range', hue='n_cores', order=price_range_counts.index, hue_order=n_cores_categories)
plt.title("n_cores v/s Price range")
plt.legend(loc='best')

"""* Price range 0 has majority of phones with 2 core processors
* Price range 1 has majority of phones with 1 and 4 core processors
* Price range 2 has majority of phones with 4 core processors
* Price range 3 has majority of phones with 5 and 7 core processors

### With bluetooth features
"""

blue_categories = list(set(data['blue']))
price_range_counts = data['price_range'].value_counts()

plt.figure(figsize=(8,3))
sns.countplot(data=data, x='price_range', hue='blue', order=price_range_counts.index, hue_order=blue_categories)
plt.title("blue v/s Price range")
plt.legend(loc='best')

"""Majority of phones of price range from 0 to 2 dont have bluetooth on other hand price range of 3 have bluetooth service.

### Plot Battery Power vs Touch Screen
"""

plt.figure(figsize=(4,3))
data.groupby(['touch_screen'])['battery_power'].mean().plot(kind = 'bar', color = cs1, rot = 0)
plt.show()

plt.figure(figsize=(4,3))
snsplot2 = sns.boxplot(x="touch_screen", y="battery_power", data=data, palette=cs1)
plt.show()

"""### Price Range with supported and unsupported feature"""

# Checking the counts of binary categorical variables by grouping price range.
grup_by_price=data.groupby(['price_range']).agg({'blue':'value_counts','dual_sim':'value_counts','four_g':'value_counts','three_g':'value_counts','touch_screen':'value_counts','wifi':'value_counts'}).unstack()

fig, ax = plt.subplots(figsize=(12, 5))
grup_by_price.plot.bar(ax=ax)
plt.title('Count of phones in each price range with supported or not supported mobile specifications.', fontsize=16)
plt.xlabel('Price range', fontsize=12)
plt.ylabel('Count of phones', fontsize=12)
plt.legend(loc='center left', bbox_to_anchor=(1, 0.5), fontsize=12)

plt.tight_layout()  # Mengoptimalkan tata letak grafik

# Menyesuaikan ukuran font pada sumbu x dan y
ax.tick_params(axis='x', labelsize=10)
ax.tick_params(axis='y', labelsize=10)

plt.show()

"""Pada masing-masing kategori harga seimbang ada yang punya fitur dan ada yang tidak punya"""

list_2 = ['n_cores', 'm_dep']

for item in list_2:
    plt.figure(figsize=(12, 3))
    ax = data.groupby(['price_range'])[item].value_counts().unstack().plot.bar()
    plt.title(f'Price range grouped by {item}')
    plt.ylabel('No. of phones')
    plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))  # Memindahkan penjelasan warna ke samping kiri

plt.show()

"""* There are very few mobiles in price range 0 and 1 with lesser no of cores.
* Most of the mobiles in price range 2 and 3 are with high no of cores.

* Number of phones with less thickness is high and count of phones with high thickness is low.

### Check numerical fitur that significan affect a price range.##
"""

list_1 = ['battery_power', 'clock_speed', 'fc', 'int_memory', 'm_dep', 'mobile_wt', 'n_cores', 'pc',
          'px_height', 'px_width', 'sc_h', 'ram', 'sc_w', 'talk_time']


# plotting boXplot and distribution
num_plots = len(list_1)
num_cols = 3

num_rows = num_plots // num_cols
if num_plots % num_cols != 0:
    num_rows += 1

fig, axes = plt.subplots(num_rows, num_cols, figsize=(15, 10))

counter = 0
for var in list_1:
    row = counter // num_cols
    col = counter % num_cols

    ax = axes[row, col] if num_rows > 1 else axes[col]

    sns.lineplot(x=data['price_range'], y=data[var], ax=ax)
    ax.set_title(f'Price range vs {var}', fontsize=12)
    ax.set_xlabel('Price range', fontsize=10)
    ax.set_ylabel(var, fontsize=10)

    counter += 1

plt.subplots_adjust(hspace=1)

plt.show()

"""* For class 1 and class2 battery power range is almost similar. As battery power increases price also increases whcih is quite obivious.
* Mobiles in very high price range(Class 3) has less weight compared to other classes.That means as weight of mobiles decrease price increases.
* Mobiles having max screen  height and width falls in very high price category. We can see in linechart of sc_width and sc_height from class 2 screen width and hieght starts increasing with price. Similar case is with px_height and px_width. As resolution of screen increases the price also increases
RAM has clear relationship with price range we saw that in correlation matrix also.
"""

# Cek jumlah data missing tiap kolom
data.isna().sum()

# Cek jumlah data terduplikasi pada dataset
data.duplicated().sum()

# Drop (menghilangkan) data missing dan duplikat dari dataset
# data = data.dropna().reset_index(drop=True)
# data = data.drop_duplicates()
# data

"""## Distribution of columns and Outliers."""

# Cek outlier dari dataset
data.plot(kind="box",subplots=True,layout=(10,10),sharex=False,sharey=False,figsize=(20,20))
plt.show()

fig, (ax1, ax2) = plt.subplots(1, 2)
fig.set_figheight(4)
fig.set_figwidth(4)
fig.tight_layout()
#fig.suptitle('Horizontally stacked subplots')

ax1.boxplot(data['fc'])
ax1.set_xlabel('kolom "fc" (Front Camera)', fontsize=12)
ax1.set_ylabel('Data pada kolom "fc"', fontsize=12)
ax1.set_xticklabels(['fc'])

ax2.boxplot(data['px_height'])
ax2.set_xlabel('kolom "px_height" (Pixel Height)', fontsize=12)
ax2.set_ylabel('Data pada kolom "px_height"', fontsize=12)
ax2.set_xticklabels(['px_height'])

plt.subplots_adjust(right=1.5)

plt.title('Outlier dari Data', x=-0.25, y=1.025, fontsize=20)
plt.show()



def showing_boxplot(data, features):
    num_plots = len(features)
    num_cols = 4  # Jumlah kolom yang ingin ditampilkan secara horizontal

    # Hitung jumlah baris yang diperlukan berdasarkan jumlah grafik dan kolom yang ingin ditampilkan
    num_rows = (num_plots + num_cols - 1) // num_cols

    # Buat subplot dengan jumlah baris dan kolom yang sesuai
    fig, axes = plt.subplots(num_rows, num_cols, squeeze=False, figsize=(16, 4*num_rows))

    for i, c in enumerate(features):
        # Hitung indeks baris dan kolom
        row = i // num_cols
        col = i % num_cols

        # 1st quartile
        Q1 = np.percentile(data[c], 25)
        # 3rd quartile
        Q3 = np.percentile(data[c], 75)
        # IQR
        IQR = Q3 - Q1
        # Outlier step
        outlier_step = IQR * 1.5
        # detect outlier and their indices
        outlier_list_col = data[(data[c] < Q1 - outlier_step) | (data[c] > Q3 + outlier_step)].index

        # Group data by "price_range" and plot boxplot
        data.boxplot(column=c, by="price_range", ax=axes[row, col])
        axes[row, col].set_title(c)  # Menambahkan judul grafik

    # Menghilangkan subplot yang tidak digunakan
    for i in range(num_plots, num_rows*num_cols):
        row = i // num_cols
        col = i % num_cols
        fig.delaxes(axes[row, col])

    plt.tight_layout()
    plt.show()

showing_boxplot(data, ["battery_power", "clock_speed", "fc", "int_memory", "m_dep", "mobile_wt",
                      "n_cores", "pc", "px_height", "px_width", "ram", "sc_h", "sc_w", "talk_time"])

"""* Data is well distrubted.
* fc and px_height has some outliers

## Handle Outliers
"""

Q1 = data["fc"].quantile(0.25)
Q3 = data['fc'].quantile(0.991)
IQR = Q3-Q1

# Outliers are present after Quartile 3. so we will take datapoints before Q3.
data = data[(data['fc'] <= Q3)]

Q1 = data["px_height"].quantile(0.25)
Q3 = data['px_height'].quantile(0.991)
IQR = Q3-Q1
# Outliers are present after Quartile 3. so we will take datapoints before Q3.
data = data[(data['px_height'] <= Q3)]

# Visualising whether oultliers are removed or not.
for var in ['fc','px_height']:
    plt.figure(figsize=(12,4))
    plt.subplot(1, 2, 1)
    fig = sns.boxplot(y=data[var],color='#7e659f')
    fig.set_title('')
    fig.set_ylabel(var)

    plt.subplot(1, 2, 2)
    fig = sns.distplot(data[var],color='#7e659f')

    fig.set_xlabel(var)

    plt.show()

"""Now in box plot no oultiers are present."""

# create copy of data
data_df=data.copy()

"""## Feature Selection"""

corr = data.corr()

plt.figure(figsize=(20, 10))
sns.heatmap(corr, annot=True, cmap='YlGnBu')

plt.show()

# Separating X variables(indpendent variables) and Y(dependent variable) variable.
x=data.drop('price_range',axis=1)
y=data["price_range"]

from sklearn.feature_selection import SelectKBest
from sklearn.feature_selection import chi2

#No we Will select the  top 12 important features
bestfeatures = SelectKBest(score_func=chi2, k=12)
fit = bestfeatures.fit(x,y)

# creating score's and coolumn's dataframe
dfscores = pd.DataFrame(fit.scores_)
dfcolumns = pd.DataFrame(x.columns)

# conacatenating above two dataframes
featureScores = pd.concat([dfcolumns,dfscores],axis=1)
featureScores.columns = ['Specs','Score']

# Check dataframe
featureScores

# 12 features with highest chi squared statistic
print(featureScores.nlargest(12,'Score'))

# 12 features with highest chi squared statistic are selected as independent variables.
X=data[['ram','px_height','battery_power','px_width','mobile_wt','int_memory','sc_h','talk_time','sc_w','fc','n_cores','pc']]

# dependent varaible
y=data['price_range']

"""# Modelling

Algorithms used for predictive modeling:
* 1) Decision Tree
* 2) Random Forest classifier
* 3) Gradient Boosting Classifier
* 4) K-nearest Neighbour classifier
* 5) XG Boost Classifier
* 6) Support Vector Machine(SVM)

As Decision tree,random forest and enssembles trees do not require Feature scaling as these are Tree based models. So we will be using X_train and X_test which are not scaled.

For K nearest Neighbors and SVM we will be usingseX_train_scaled and X_test_scaled. That is we we will use Standardised data. i.e. Scaled data. As these are distance based Algorithms.
"""

!pip uninstall scikit-learn -y
!pip install scikit-learn

pip install --upgrade scikit-learn

# importing all essential libraries.
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler,MinMaxScaler

from sklearn.metrics import accuracy_score, classification_report, ConfusionMatrixDisplay,confusion_matrix,roc_curve,roc_auc_score,auc
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.ensemble import GradientBoostingClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import AdaBoostClassifier
from xgboost import XGBClassifier
from sklearn.model_selection import GridSearchCV
from sklearn.metrics import confusion_matrix

# splitting the data into Train and test data
X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.25, random_state=0)
print(X_train.shape)
print(X_test.shape)
print(y_train.shape)

# Scaling the data.
# creating an object of MinMax Scaler
scaler=StandardScaler()
X_train_scaled=scaler.fit_transform(X_train)   # fitting the X_train
X_test_scaled=scaler.transform(X_test)         # transforming X_test

# Defining a fucnction for plotting roc curve
def plot_Auc_roc(y_test,pred_prob):
  '''It will take y_test and y predicted probabilities
  as input and will plot the roc curve.'''

  fpr = {}
  tpr = {}
  thresh ={}

  n_class = 4

  for i in range(n_class):
      fpr[i], tpr[i], thresh[i] = roc_curve(y_test, pred_prob[:,i], pos_label=i)

  # plotting
  plt.figure(figsize=(12,8))
  plt.plot(fpr[0], tpr[0], linestyle='--',color='orange', label= ((f'Class 0(Low cost) vs Rest, AUC= {round(auc(fpr[0],tpr[0]),4)}')))
  plt.plot(fpr[1], tpr[1], linestyle='--',color='green', label=((f'Class 1(Medium cost) vs Rest, AUC= {round(auc(fpr[1],tpr[1]),4)}')))
  plt.plot(fpr[2], tpr[2], linestyle='--',color='blue', label=((f'Class 2(High cost) vs Rest, AUC= {round(auc(fpr[2],tpr[2]),4)}')))
  plt.plot(fpr[3], tpr[3], linestyle='--',color='red', label=((f'Class 3(Very High cost) vs Rest, AUC= {round(auc(fpr[3],tpr[3]),4)}')))
  plt.title('Multiclass ROC curve')
  plt.xlabel('False Positive Rate')
  plt.ylabel('True Positive rate')
  plt.legend(loc='best')
  plt.savefig('Multiclass ROC',dpi=300);

# creating a class list
Class_cat = ['low cost','medium cost', 'high cost', 'very high cost']

"""## **1)Decision Tree Classifier:**

**Decision trees and ensemble methods do not require feature scaling to be performed as they are not sensitive to the the variance in the data.**
**So here we will use X_train,X_test,y_test and Y_train which are not scaled.**

Decision Tree with default hyperparameters:
"""

# Creating object of the decision tree.
dtc=DecisionTreeClassifier(random_state=0)

# fitting/training the train set.
dtc.fit(X_train,y_train)

# Predicting y values of train and test data.
y_train_pred=dtc.predict(X_train)
y_pred=dtc.predict(X_test)

# Checking train set accuracy.
accuracy_score(y_train,y_train_pred)

# Checking test set accuracy
accuracy_score(y_test,y_pred)

# Confusion matrix for test set.
cf_matrix=confusion_matrix(y_test,y_pred)
cf_matrix

y_pred = dtc.predict(X_test)
cm = confusion_matrix(y_test, y_pred)
cmd = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=Class_cat)
cmd.plot(cmap='coolwarm', xticks_rotation='vertical')

# printing classification report for train set.
print(classification_report(y_train,y_train_pred))

# printing classification of test set.
print(classification_report(y_test,y_pred))

"""* Train set accuracy is 100% and test accuracy is 85%.
* Model is overfitted on train set and did not generalised well.
* We will tune hyperparamters to reduce overfitting and try to imporve the model performance.

### Tuning Hyperparameters of Decsion Tree classifier
"""

# creating an object of classifier.
dtc_= DecisionTreeClassifier(random_state=0)

# paramter grid values for hyperparameter tunning.
grid_values={'criterion':['gini','entropy'],
             'max_depth':[2,3,4,5,6,9,10,11,12,13,14,15],
             'splitter':['best','random'],
             'min_samples_split':[3,5,10],
             'max_features':['auto','sqrt','log2',None]}

# applying GridSearchCv and fitting the model with it.
dtc_tune=GridSearchCV(dtc_,param_grid=grid_values,cv=5,scoring='accuracy',verbose=3)
dtc_tune.fit(X_train,y_train)   # model fitting.

# best parameters for model.
dtc_tune.best_params_

# getting best estimators
dtc_tune.best_estimator_

# using best parameters and training the the data.
dtc_optimal=DecisionTreeClassifier(criterion='entropy', max_depth=9, min_samples_split=10,
                       random_state=0)
dtc_optimal.fit(X_train,y_train)

# predicting y values of train and test set.
y_train_pred=dtc_optimal.predict(X_train)
y_pred=dtc_optimal.predict(X_test)

# Checking the accuracy score of train set.
accuracy_score(y_train,y_train_pred)

# Checking the accuracy score of test set.
accuracy_score(y_test,y_pred)

# getting confusion matrix for test set.
cf_matrix=confusion_matrix(y_test,y_pred)
cf_matrix

y_pred = dtc_optimal.predict(X_test)
cm = confusion_matrix(y_test, y_pred)
cmd = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=Class_cat)
fig, ax = plt.subplots(figsize=(8, 6))
cmd.plot(ax=ax, cmap='coolwarm', xticks_rotation='vertical')
ax.grid(False)
ax.set_title('Confusion Matrix - Test Set', fontsize=15)
plt.show()

# printing classification report for train set.
print(classification_report(y_train,y_train_pred))

# printing classification report for test set.
print(classification_report(y_test,y_pred))

# creating a function for plotting the feature importances.
def plot_feature_importance(algo):
  ''' Takes the alogorithm as input and
  plots the feature importance graph'''

  # get importance
  importance = algo.feature_importances_
  feat_importance=pd.DataFrame({'Features':X.columns,'score':importance}).sort_values(by='score',ascending=False)
  plt.figure(figsize=(10,8))
  sns.barplot(x=feat_importance['score'],y=feat_importance['Features'])
  plt.title('Feature Importance')

# Plot AUC ROC curve.
pred_prob = dtc_optimal.predict_proba(X_test)
plot_Auc_roc(y_test,pred_prob)

"""**Decision Tree Classifier-Observations:**
* ***Train accuarcy has been reduced to 98% from 100% and so test accuarcy is decreased by 1% . Thus we somewhat reduced the overfiiting by reducing the training accuarcy. However this will not be good model.***

* ***RAM,battery power,px_height and width came out to be the most important featrures***
* ***This model classified the class 0 and class 3 very nicely as we can see the AUC is almost 0.96 for both classes,whereas for class 1 and class 2 it is 0.88.***

## 2) Random Forest classifier:

With default hyperparamters:
"""

# splitting the data into trainset and test set.
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=0)

# creating an object of the classifier.
rfc=RandomForestClassifier(random_state=0)

# fitting/training the model.
rfc.fit(X_train,y_train)

# predicting the y values of train set and test set.
y_train_pred=rfc.predict(X_train)
y_pred=rfc.predict(X_test)

# Checking the accuarcy score of train set.
accuracy_score(y_train,y_train_pred)

# Checking the accuracy score of test set.
accuracy_score(y_test,y_pred)

# Confusion matrix for test set.
cf_matrix=confusion_matrix(y_test,y_pred)
cf_matrix

y_pred = rfc.predict(X_test)
cm = confusion_matrix(y_test, y_pred)
cmd = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=Class_cat)
cmd.plot(cmap='coolwarm', xticks_rotation='vertical')
plt.title('Confusion Matrix-testset', fontsize=15)
plt.show()

# printing the classification report for train set.
print(classification_report(y_train,y_train_pred))

# printing the classification report for train set.
print(classification_report(y_test,y_pred))

"""* Train accuarcy is 100% and test accuracy is 89%. which is quite good. But model seems to be overfitted and has not generalised the data well. We need to reduce overfitting and improve the model performance.
* we do some hyperparameter tunning to reduce overfitting

### Hyperparamter Tunning of the Random forest model
"""

# para_grid values to pass in gridsearchcv.
grid_values={'n_estimators':[300, 400, 500, 700],
          'max_depth':[None, 10, 20, 40],
          'min_samples_split':[2,6,10],
          'max_leaf_nodes':[None],
          'criterion':['entropy','gini'],
          'max_features':['auto','log2','sqrt']

             }

# creating the instance
rfc_= RandomForestClassifier(random_state=0)

# Applying GridSearchCV
rfc_tune=GridSearchCV(rfc_,param_grid=grid_values,cv=3,verbose=3,scoring='accuracy')
rfc_tune.fit(X_train,y_train)

#Getting best paramters for the models
rfc_tune.best_params_

# fitting/training the data with best parameters.
rfc_optimal=RandomForestClassifier(max_features='auto',criterion='entropy',max_depth=None,max_leaf_nodes=None,min_samples_split=6,n_estimators=700,random_state=0)
rfc_optimal.fit(X_train,y_train)

# predicting y values of train and test set.
y_train_pred=rfc_optimal.predict(X_train)
y_pred=rfc_optimal.predict(X_test)

# checking the train accuracy score.
accuracy_score(y_train,y_train_pred)

# checking the test accuracy score.
accuracy_score(y_test,y_pred)

# getting confusion matrix
cf_matrix=confusion_matrix(y_test,y_pred)
cf_matrix

y_pred = rfc_optimal.predict(X_test)
cm = confusion_matrix(y_test, y_pred)
cmd = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=Class_cat)
cmd.plot(cmap='coolwarm', xticks_rotation='vertical')
plt.title('Confusion Matrix-testset', fontsize=15)
plt.show()

# printing the classification report for train set
print(classification_report(y_train,y_train_pred))

# printing the classification report for train set
print(classification_report(y_test,y_pred))

#plotting feature importances
plot_feature_importance(rfc_optimal)

# Plot AUC ROC curve.
pred_prob = rfc_optimal.predict_proba(X_test)
plot_Auc_roc(y_test,pred_prob)

"""###**Observations of Random Forest:**
***Before Tuning***
* ***training accuarcy = 100%***
* ***test accuarcy = 88%***

***Model is overfitted the data and does not generalised well. So we tuned the hyperparameters.***

***After tuning:***
* ***Training accuarcy= 100%***
* ***Test accuarcy = 90%***

***we have slightly improved the model and overfitting is reduced slightly.***

***From roc curve its clear that model has poorly performed to classify class 1 and class 2.***

## **3)Gradient Boosting Classifier:**

**With default hyperparameters:**
"""

# Train test split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=0)

# creating an object of the classifier
gbc=GradientBoostingClassifier(random_state=0)

# fittng/training the data.
gbc.fit(X_train,y_train)

# predicting y values of train and test set.
y_train_pred=gbc.predict(X_train)
y_pred=gbc.predict(X_test)

# checking the accuracy score of train data.
accuracy_score(y_train,y_train_pred)

# checking the accuracy score of test data.
accuracy_score(y_test,y_pred)

# confusion matrix
cf_matrix=confusion_matrix(y_test,y_pred)
cf_matrix

y_pred = gbc.predict(X_test)
cm = confusion_matrix(y_test, y_pred)
cmd = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=Class_cat)
cmd.plot(cmap='coolwarm', xticks_rotation='vertical')
plt.title('Confusion Matrix-testset', fontsize=15)
plt.show()

# printing the classification report for train set
print(classification_report(y_train,y_train_pred))

# printing the classification report for train set
print(classification_report(y_test,y_pred))

"""### Hyperparameter tuning"""

# Creating an object of the classifier
gbc=GradientBoostingClassifier(random_state=0)

# para_grid values to pass in gridsearchcv.
grid_values={'learning_rate':[0.005,1,2,3],
             'min_samples_split':range(10,26)

             }

# Applying GridSearchCV
gbc_tune=GridSearchCV(gbc,param_grid=grid_values,cv=3,verbose=1,scoring='accuracy')
gbc_tune.fit(X_train,y_train)

# Getting best parameters
gbc_tune.best_params_

# getting best estimators
gbc_tune.best_estimator_

# aplying best estimarors
gbc_optimal=GradientBoostingClassifier(learning_rate=1,random_state=0,min_samples_split=25)
gbc_optimal.fit(X_train,y_train)

# predicting the y values of train and test set.
y_train_pred=gbc_optimal.predict(X_train)
y_pred=gbc_optimal.predict(X_test)

# train set accuracy score
accuracy_score(y_train,y_train_pred)

# test set accuracy score
accuracy_score(y_test,y_pred)

# confusion matrix
cf_matrix=confusion_matrix(y_test,y_pred)
cf_matrix

y_pred = gbc_optimal.predict(X_test)
cm = confusion_matrix(y_test, y_pred)
cmd = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=Class_cat)
cmd.plot(cmap='coolwarm', xticks_rotation='vertical')
plt.title('Confusion Matrix-testset', fontsize=15)
plt.show()

# printing the classification report of train set.
print(classification_report(y_train,y_train_pred))

# printing the classification report of test set.
print(classification_report(y_test,y_pred))

#plotting feature importances
plot_feature_importance(gbc_optimal)

# Plot AUC ROC curve.
pred_prob = gbc_optimal.predict_proba(X_test)
plot_Auc_roc(y_test,pred_prob)

"""### **Results of Gradient Boost Classifiers:**

Before tunning:
* Train accuracy score= 100%.
* Test accuracy score= 89%

Model did not generalised well and overfitted the training data. so we tuned hyperparameters of model.

After Hyperparameter Tuning
* Train accuracy score= 100%
* Test accuarcy score=90%

Thus we slightly improved the model performance.However the model is not best.





From ROC curve it's clear that model was good to classify the class 0 and class 3.From the classification report its clear that recall for class 0 and class 3 is also good which is 99.5% and 99.7% respectively.

## **4) K Nearest Neighbors**

With default hyperparameters:
"""

knn=KNeighborsClassifier()     # creating an object of the classifier
knn.fit(X_train_scaled,y_train)   #  fitting the data

# predicting the y values of train and test set.
y_train_pred=knn.predict(X_train_scaled)
y_pred=knn.predict(X_test_scaled)

# checking the accuracy score of train set
accuracy_score(y_train,y_train_pred)

# Checking the accuracy score of test set.
accuracy_score(y_test,y_pred)

# confusion matrix
cf_matrix=confusion_matrix(y_test,y_pred)
cf_matrix

y_pred = knn.predict(X_test_scaled)
cm = confusion_matrix(y_test, y_pred)
cmd = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=Class_cat)
cmd.plot(cmap='coolwarm', xticks_rotation='vertical')
plt.title('Confusion Matrix-testset', fontsize=15)
plt.show()

# printing the classification report of test set.
print(classification_report(y_train,y_train_pred))

# printing the classification report of test set.
print(classification_report(y_test,y_pred))

# Plot AUC ROC curve.
pred_prob = knn.predict_proba(X_test_scaled)
plot_Auc_roc(y_test,pred_prob)

"""### HyperParameter tuning."""

# creating an object of classifier
knn=KNeighborsClassifier()

# parameter grid values.
grid_values = {'n_neighbors':list(range(1, 31))}

# applyong GridSearchCv with above grid values and cv=5
knn_tune=GridSearchCV(knn,cv=5,scoring='accuracy',verbose=3,param_grid=grid_values)
knn_tune.fit(X_train_scaled,y_train)

# getting thge best parameters
knn_tune.best_params_                     # thus  best n_neighnors came out to be 29

# fitting the data with best parameters
knn_optimal=KNeighborsClassifier(n_neighbors=29)
knn_optimal.fit(X_train_scaled,y_train)

# predicting y values of train and test set.
y_train_pred=knn_optimal.predict(X_train_scaled)
y_pred=knn_optimal.predict(X_test_scaled)

#checking the accuracy score of train set.
accuracy_score(y_train,y_train_pred)

# checking the accuracy score of test set.
accuracy_score(y_test,y_pred)

# confusion matrix
cf_matrix=confusion_matrix(y_test,y_pred)
cf_matrix

y_pred = knn_optimal.predict(X_test_scaled)
cm = confusion_matrix(y_test, y_pred)
cmd = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=Class_cat)
cmd.plot(cmap='coolwarm', xticks_rotation='vertical')
plt.title('Confusion Matrix-testset', fontsize=15)
plt.show()

# printig tye classification report of train set.
print(classification_report(y_train,y_train_pred))

# printing the classification report of test set.
print(classification_report(y_test,y_pred))

# Plot AUC ROC curve.
pred_prob = knn_optimal.predict_proba(X_test_scaled)
plot_Auc_roc(y_test,pred_prob)

"""### **Results:**
***Before hyperparameters tuning:***

* Train Accuracy:70 %
* Test Accuarcy:52 %

Clearly Model has performed very worst. We did hyperparameter tuning

After Hyperparameter Tuning:

* Train Accuarcy: 68%
* Test Accuarcy: 59%

Although we improved the model perfromance and reduced overfitting but however this is not  good model.

## **5) XGBoost Classifier:**

With default hyperparameter
"""

# spltting the data into train test split.
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=0)

xgb=XGBClassifier()        # creating an object of the classifier
xgb.fit(X_train,y_train)      # fitting the data

# predicting y values of train and test data.
y_train_pred=xgb.predict(X_train)
y_pred=xgb.predict(X_test)

# checking the accuracy score of train set
accuracy_score(y_train,y_train_pred)

# checking the accuracy score of test data.
accuracy_score(y_test,y_pred)

# confusion matrix
cf_matrix=confusion_matrix(y_test,y_pred)
cf_matrix

# printing the classification report of train set
print(classification_report(y_train,y_train_pred))

# printing the classification report of the test set
print(classification_report(y_test,y_pred))

"""Train accuracy = 100% Test Accuarcy= 89 %

###  Hyperparameter tuning:
"""

# parameter grid values for GridSearchCv
grid_values={
          'learning_rate':[0.6,1],
          'n_estimators':[500,1000],
          'gamma':[0.2],
          'subsample':[0.5,0.6]
          }

# creating an object of the classifier
xgb = XGBClassifier()

# applying girdsearchcv
xgb_tune = GridSearchCV(xgb, grid_values, cv=3,verbose=4)
xgb_tune.fit(X_train,y_train)

xgb_tune.best_params_

xgb_opti=XGBClassifier(learning_rate=.6,gamma=0.2,n_estimators=1000,subsample=0.5)
xgb_opti.fit(X_train,y_train)

y_train_pred=xgb_opti.predict(X_train)
y_pred=xgb_opti.predict(X_test)

accuracy_score(y_train,y_train_pred)

accuracy_score(y_test,y_pred)

cf_matrix=confusion_matrix(y_test,y_pred)
cf_matrix

y_pred = xgb_opti.predict(X_test)

cm = confusion_matrix(y_test, y_pred)
cmd = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=Class_cat)
cmd.plot(cmap='coolwarm', xticks_rotation='vertical')
plt.title('Confusion Matrix-testset', fontsize=15)
plt.show()

#printing the classifiaction report of train set.
print(classification_report(y_train,y_train_pred))

#printing the classifiaction report of test set.
print(classification_report(y_test,y_pred))

#plotting feature importances
plot_feature_importance(xgb_opti)

# Plot AUC ROC curve.
pred_prob = xgb_opti.predict_proba(X_test)
plot_Auc_roc(y_test,pred_prob)

"""### **Results**

***Before hyperparameter Tuning***
* ***Train Accuarcy = 100%***
* ***Test Accuarcy = 89%***

***After hyperparameter Tuning***
* ***Train Accuarcy = 100%***
* ***Test Accuarcy = 91%***

***we have improved the model performance by Hyperparamter tuning. Test accuracy is increased to 91%.But still the difference of accuracy score between train and test is  more than 5%.We can say model is very slightly overfitted***

***From AUC-ROC curve its clear that model has almost correctly predicted the class 0 and class 3.***

## 6) SVM

with default parameters.
"""

# Import all relevant libraries
from sklearn.svm import SVC

svc = SVC(random_state= 1)      # creating an object of classifier
svc.fit(X_train_scaled,y_train)    # fitting the model/training the model.

# predicting the y value of train set and test set
y_train_pred=svc.predict(X_train_scaled)
y_pred=svc.predict(X_test_scaled)

# Accuracy score for train set
accuracy_score(y_train,y_train_pred)

# Accuracy score for test set.
accuracy_score(y_test,y_pred)

cf_matrix=confusion_matrix(y_test,y_pred)
cf_matrix

y_pred = svc.predict(X_test_scaled)
cm = confusion_matrix(y_test, y_pred)
cmd = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=Class_cat)
cmd.plot(cmap='coolwarm', xticks_rotation='vertical')
plt.title('Confusion Matrix-testset', fontsize=15)
plt.show()

#printing the classifiaction report of train set.
print(classification_report(y_train,y_train_pred))

#printing the classifiaction report of train set.
print(classification_report(y_test,y_pred))

"""### Hyperparameter Tuning"""

# parameter grid for GridSearchCv
grid_values = {
    'C':[0.01,0.1,1,10],
    'kernel' : ["linear","poly","rbf","sigmoid"],
    'degree' : [1,3,5,7],
    'gamma' : [0.01,1]
}

# creating an object for classifier
svm  = SVC ()

# Hyperparameter tuning with the GrdiSearhCV with cv=5
svm_cv = GridSearchCV(svm, grid_values, cv = 5,verbose=2)
svm_cv.fit(X_train_scaled,y_train)     # fitting the data into the model

# getting the best parameters
svm_cv.best_params_

# getting the best estimators
svm_cv.best_estimator_

# applying best parameters to the SVm model.
svm_optimal=SVC(C=10, degree=1, gamma=0.01, kernel='linear',probability=True)
svm_optimal.fit(X_train_scaled,y_train)   # fitting the data

# predicting the y values of train and test set.
y_train_pred=svm_optimal.predict(X_train_scaled)
y_pred=svm_optimal.predict(X_test_scaled)

# checking the accuracy of test data
accuracy_score(y_test,y_pred)

# Confusion matrix
cf_matrix=confusion_matrix(y_test,y_pred)
cf_matrix

y_pred = svm_optimal.predict(X_test_scaled)
cm = confusion_matrix(y_test, y_pred)
cmd = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=Class_cat)
cmd.plot(cmap='coolwarm', xticks_rotation='vertical')
plt.title('Confusion Matrix-testset', fontsize=15)
plt.show()

#printing the classifiaction report of train set.
print(classification_report(y_train,y_train_pred))

#printing the classifiaction report of train set.
print(classification_report(y_test,y_pred))

# Plot AUC ROC curve.
pred_prob = svm_optimal.predict_proba(X_test_scaled)
plot_Auc_roc(y_test,pred_prob)

"""### **Results**


* ***Accuracy score on train set is 99% and Test score is 88%.***
***Model seems to be overfitted as the differance between train and test accuracy score is almot 100%.***
* ***After Hyperparameter tuning train accuracy remained almost same  98% and test accuracy score increased to 97%.***
*  ***SVM performed very well as compared to other alogorithms.***
* ***In terms of feature importance RAM,Battery power,px_height and px_weight are the imporatant features.***
* ***f1 score for individual classes is also very good. Area under curve for each class prediction is also almost 100%***

===============================================================================================
"""